# Multilayer Perceptron (MLP)

Implementation of multilayer perceptron/neural network from scratch to understand and grasp basic concepts of Deep Learning.

Requirements:
1. numpy
2. matplotlib
3. scikit-learn

Output plots:
1. Generated dataset for classification  
<img src="https://github.com/subham-agrawall/neural-network-scratch/blob/master/plots/output1_data.png" width="400" height="300">  


2. Decision boundary from Logistic Regression model  
<img src="https://github.com/subham-agrawall/neural-network-scratch/blob/master/plots/output2_LR.png" width="400" height="300">  


3. Decision boundary from MLP with hidden layer size = 3  
<img src="https://github.com/subham-agrawall/neural-network-scratch/blob/master/plots/output3_MLP.png" width="400" height="300">  


4. Variation in decision boundary with hidden layer size  
<img src="https://github.com/subham-agrawall/neural-network-scratch/blob/master/plots/output4_hiddenlayers.png" width="400" height="300">  


This exercise shows the capability of neural network to form non-linear decision boundaries where logistic regression fails through an example. Also, shows the variation in decision boundary as we increase the number of nodes in hidden layer.
